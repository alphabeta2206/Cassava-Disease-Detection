{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, shutil,math,re\nimport json\nfrom keras import layers, models, optimizers\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom matplotlib import pyplot as plt\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, smart_resize\nfrom keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau, ModelCheckpoint\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport PIL\nfrom kaggle_datasets import KaggleDatasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport warnings\ndef seed_everything(seed=0):\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n\nseed = 21\nseed_everything(seed)\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print(\"Running on TPU \", tpu.cluster_spec().as_dict()[\"worker\"])\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept ValueError:\n    print(\"Not connected to a TPU runtime. Using CPU/GPU strategy\")\n    strategy = tf.distribute.MirroredStrategy()\n\ntry: \n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() \n    strategy = tf.distribute.TPUStrategy(tpu)\nexcept ValueError: # detect GPUs\n    strategy = tf.distribute.MirroredStrategy() \n\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_size = (512,512)\nn_CLASS = 5\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nprint('Batch size:', BATCH_SIZE)\nepochs=12","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gcs_path = KaggleDatasets().get_gcs_path(f'cassava-leaf-disease-classification')\nprint(gcs_path)\n\ntraining_files = tf.io.gfile.glob(gcs_path + '/train_tfrecords/*.tfrec')\n\nprint('Training tfrecords: '+ str(len(training_files)))\n\n\ndef count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\nNUM_TRAINING_IMAGES = count_data_items(training_files)\n\nprint('Dataset: {} training images '.format(NUM_TRAINING_IMAGES))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"work_dir = '../input/cassava-leaf-disease-classification/'\ndata = pd.read_csv(work_dir + 'train.csv')\nwith open(work_dir+ 'label_num_to_disease_map.json') as js:\n    classes = json.load(js)\nprint(classes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_label_distribution(label_count):\n    fig, ax = plt.subplots(1, 1, figsize=(20, 8))\n    ax = sns.countplot(y=label_count, palette='deep')\n    ax.tick_params(labelsize=16)\n    \nshow_label_distribution(data['label'].values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#decode_image - For converting bytestring images into arrays.\n#read_labeled_tfrecord - Returns image & label from the tfrecords.\n#read_labeled_tfrecord_with_imageid - Returns image, label & image id from the tfrecords.\n#read_unlabeled_tfrecord - Returns image & image id.\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)  \n    image = tf.reshape(image, [*image_size, 3]) \n    return image\n\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"target\": tf.io.FixedLenFeature([], tf.int64), \n        \"image\": tf.io.FixedLenFeature([], tf.string),\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    \n    image = decode_image(example['image'])\n    label = tf.cast(example['target'], tf.int32)\n\n    return image, label\n\n\ndef read_labeled_tfrecord_with_imageid(example):\n    LABELED_TFREC_FORMAT_WITH_ID = {\n        \"target\": tf.io.FixedLenFeature([], tf.int64),  \n        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n        \"image\": tf.io.FixedLenFeature([], tf.string), \n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT_WITH_ID)\n    \n    image = decode_image(example['image'])\n    label = tf.cast(example['target'], tf.int32)\n    image_name = example['image_name']\n    \n    return image, label, image_name \n\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        'image_name' : tf.io.FixedLenFeature([], tf.string),\n        'image' : tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    \n    image = decode_image(example['image'])\n    image_name = example['image_name']\n    \n    return image, image_name","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_im(fig, row, col, index, path=None, image=None, title=None, title_color='white'):\n    if image is not None:\n      image = image\n    elif path is not None:\n      image = PIL.Image.open(path)   \n    ax = fig.add_subplot(row, col, index)\n    ax.set_xticks([]), ax.set_yticks([])  \n    ax.imshow(image)\n    \n    if title:\n        plt.title(title,\n                  color=title_color)\n        \n    fig.tight_layout(pad=0.02)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False \n\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) \n    dataset = dataset.with_options(ignore_order) \n    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n\n    return dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Splitting The dataset into Training and Testing data\ntemp_training_ds = load_dataset(training_files, labeled=True, ordered=True)\n\nprint(temp_training_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_targets = np.array([ target.numpy() for _, target in iter(temp_training_ds) ])\nX_indices = np.arange(len(y_targets))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train_indices, X_test_indices, y_train_targets, y_test_targets = train_test_split(\n    X_indices, y_targets, test_size=0.05, stratify=y_targets, random_state=53)\n\nprint(len(y_train_targets))\nprint(len(y_test_targets))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_selected_dataset(ds, X_indices_np): \n    X_indices_ts = tf.constant(X_indices_np, dtype=tf.int64)\n    \n    def is_index_in(index, rest):\n        return tf.math.reduce_any(index == X_indices_ts)\n    \n    def drop_index(index, rest):\n        return rest\n\n    selected_ds = ds \\\n        .enumerate() \\\n        .filter(is_index_in) \\\n        .map(drop_index)\n    \n    return selected_ds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"splitted_train_ds = get_selected_dataset(temp_training_ds, X_train_indices)\nsplitted_test_ds = get_selected_dataset(temp_training_ds, X_test_indices)\n\nprint(splitted_train_ds)\nprint(splitted_test_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_augment(image, target):\n    \n    #Random Flipping\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    \n    return image, target","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_training_dataset():\n    dataset = splitted_train_ds\n    dataset = dataset.repeat() \n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n    dataset = dataset.prefetch(AUTO) \n    \n    return dataset\n\ndef get_test_dataset():\n    dataset = splitted_test_ds\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTO) \n    \n    return dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_TRAINING_IMAGES = len(y_train_targets)\nNUM_VALIDATION_IMAGES = len(y_test_targets)\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\nprint('Dataset: {} training images, {} validation images'.format(\n    NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Training data shape:\")\nfor image, label in get_training_dataset().take(3):\n    print(image.numpy().shape, label.numpy().shape)\nprint(\"Test data label examples:\", label.numpy())\n\nprint(\"Test data shape:\")\nfor image, label in get_test_dataset().take(3):\n    print(image.numpy().shape, label.numpy().shape)\nprint(\"Test data label examples:\", label.numpy())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dataset_to_numpy_util(dataset, N):\n    dataset = dataset.unbatch().batch(N)\n    for images, labels in dataset:\n        numpy_images = images.numpy()\n        numpy_labels = labels.numpy()\n        break;\n        \n    return numpy_images, numpy_labels\n\ndef display_single(image,subplot, red=False):\n    plt.subplot(subplot)\n    plt.axis('off')\n    plt.imshow(image)\n    return subplot+1\n  \ndef display_sample_images(dataset):\n    subplot=331\n    plt.figure(figsize=(13,13))\n    images, labels = dataset_to_numpy_util(dataset, 9)\n    for i, image in enumerate(images):\n        subplot = display_single(image,subplot)\n        if i >= 8:\n            break;\n              \n    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_sample_images(get_test_dataset())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_sample_images(get_training_dataset())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import GlobalAveragePooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom keras.optimizers import RMSprop, Adam\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.applications import EfficientNetB4\nimport tensorflow_addons as tfa\n\n\nwith strategy.scope():\n    \n    #inputs = keras.Input(shape=(*image_size, 3))\n    \n   #data_augmentation = tf.keras.Sequential([\n      #layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n      #layers.experimental.preprocessing.RandomRotation(0.2),\n    #])\n    loss_function=tf.keras.losses.SparseCategoricalCrossentropy(\n        from_logits = False,\n        name='sparse_categorical_crossentropy'\n    )\n    #pre_weights=\"../input/cassava-leaf-disease-efficientnetb4/efficientnetb4_noisystudent_notop.h5/efficientnetb4_noisystudent_notop.h5\"\n    \n    pre_weights=\"imagenet\"\n    \n    effnet_b4=EfficientNetB4(input_shape = (*image_size, 3), \n        weights = pre_weights, include_top = False,\n        drop_connect_rate=0.4)\n    \n    #for layer in reversed(effnet_b4.layers):\n        #if isinstance(layer, tf.keras.layers.BatchNormalization):\n            #layer.trainable = False\n        #else:\n            #layer.trainable = True\n    \n    model = keras.Sequential([\n        #inputs,\n        #data_augmentation,\n        effnet_b4,\n        keras.layers.GlobalAveragePooling2D(),\n        keras.layers.Flatten(),\n        keras.layers.Dense(len(classes),\n            activation='softmax')\n    ])\n\n    model.compile(loss= loss_function, \n                  optimizer= keras.optimizers.Adam(lr=1e-3), \n                  metrics= ['accuracy'],\n                 )\n\nprint(model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\ntic = time.time()\n\ncheckpoint_cb = ModelCheckpoint(\n        \"Cassava_best_model.h5\",\n        save_best_only=True,\n        monitor='val_loss',\n        mode='min',\n    )\n\nlearning_rate=ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.2,\n        patience=2,\n        min_lr=1e-6,\n        mode='min',\n        verbose=1,\n    )\n\nes = EarlyStopping(\n        monitor='val_loss', \n        mode='min', \n        patience=3,\n        restore_best_weights=True, \n        verbose=1,\n    )\n\nHistory=model.fit(\n        get_training_dataset(),\n        validation_data=get_test_dataset(),\n        epochs=25,\n        steps_per_epoch=STEPS_PER_EPOCH,\n        batch_size=BATCH_SIZE,\n        callbacks=[es, checkpoint_cb, learning_rate],\n    )\n\ntoc = time.time()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"model training took {int((toc - tic) / 60)} minutes\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Training Accuracy :{ max(History.history['accuracy'])}\")\nprint(f\"Testing Accuracy :{ max(History.history['val_accuracy'])}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def trai_test_plot(acc, test_acc, loss, test_loss):\n    \n    fig, (ax1, ax2) = plt.subplots(1,2, figsize= (15,10))\n    fig.suptitle(\"Model's metrics comparisson\", fontsize=20)\n\n    ax1.plot(range(1, len(acc) + 1), acc)\n    ax1.plot(range(1, len(test_acc) + 1), test_acc)\n    ax1.set_title('History of Accuracy', fontsize=15)\n    ax1.set_xlabel('Epochs', fontsize=15)\n    ax1.set_ylabel('Accuracy', fontsize=15)\n    ax1.legend(['training', 'validation'])\n\n\n    ax2.plot(range(1, len(loss) + 1), loss)\n    ax2.plot(range(1, len(test_loss) + 1), test_loss)\n    ax2.set_title('History of Loss', fontsize=15)\n    ax2.set_xlabel('Epochs', fontsize=15)\n    ax2.set_ylabel('Loss', fontsize=15)\n    ax2.legend(['training', 'validation'])\n    plt.show()\n    \n\ntrai_test_plot(\n    History.history['accuracy'],\n    History.history['val_accuracy'],\n    History.history['loss'],\n    History.history['val_loss']\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils import  plot_model\nmodel_plot=EfficientNetB4()\nplot_model(model_plot)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}